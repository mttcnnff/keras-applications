{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mttcnnff/keras-applications/blob/master/mattsmbv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctaFWBQK0rTT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2dfe683-aec9-4529-8a59-b4c80f589274"
      },
      "source": [
        "!rm -rf keras-applications\n",
        "!rm *.*"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '*.*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyQms18Izy8_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ac250553-0621-43a0-ea06-cd7a1dd78e92"
      },
      "source": [
        "!git clone https://github.com/mttcnnff/keras-applications.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-applications'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)   \u001b[K\rremote: Counting objects:  40% (2/5)   \u001b[K\rremote: Counting objects:  60% (3/5)   \u001b[K\rremote: Counting objects:  80% (4/5)   \u001b[K\rremote: Counting objects: 100% (5/5)   \u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 458 (delta 1), reused 0 (delta 0), pack-reused 453\u001b[K\n",
            "Receiving objects: 100% (458/458), 434.91 KiB | 4.31 MiB/s, done.\n",
            "Resolving deltas: 100% (325/325), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNQcC_IwTD4I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "290f33e3-15b7-4de0-dc69-ff3304a6dee1"
      },
      "source": [
        "!mv keras-applications/keras_applications ."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot move 'keras-applications/keras_applications' to './keras_applications': Directory not empty\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twVJQism0Gk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhJPi9s5z5pc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"MobileNet v2 models for Keras.\n",
        "\n",
        "MobileNetV2 is a general architecture and can be used for multiple use cases.\n",
        "Depending on the use case, it can use different input layer size and\n",
        "different width factors. This allows different width models to reduce\n",
        "the number of multiply-adds and thereby\n",
        "reduce inference cost on mobile devices.\n",
        "\n",
        "MobileNetV2 is very similar to the original MobileNet,\n",
        "except that it uses inverted residual blocks with\n",
        "bottlenecking features. It has a drastically lower\n",
        "parameter count than the original MobileNet.\n",
        "MobileNets support any input size greater\n",
        "than 32 x 32, with larger image sizes\n",
        "offering better performance.\n",
        "\n",
        "The number of parameters and number of multiply-adds\n",
        "can be modified by using the `alpha` parameter,\n",
        "which increases/decreases the number of filters in each layer.\n",
        "By altering the image size and `alpha` parameter,\n",
        "all 22 models from the paper can be built, with ImageNet weights provided.\n",
        "\n",
        "The paper demonstrates the performance of MobileNets using `alpha` values of\n",
        "1.0 (also called 100 % MobileNet), 0.35, 0.5, 0.75, 1.0, 1.3, and 1.4\n",
        "\n",
        "For each of these `alpha` values, weights for 5 different input image sizes\n",
        "are provided (224, 192, 160, 128, and 96).\n",
        "\n",
        "\n",
        "The following table describes the performance of\n",
        "MobileNet on various input sizes:\n",
        "------------------------------------------------------------------------\n",
        "MACs stands for Multiply Adds\n",
        "\n",
        " Classification Checkpoint| MACs (M) | Parameters (M)| Top 1 Accuracy| Top 5 Accuracy\n",
        "--------------------------|------------|---------------|---------|----|-------------\n",
        "| [mobilenet_v2_1.4_224]  | 582 | 6.06 |          75.0 | 92.5 |\n",
        "| [mobilenet_v2_1.3_224]  | 509 | 5.34 |          74.4 | 92.1 |\n",
        "| [mobilenet_v2_1.0_224]  | 300 | 3.47 |          71.8 | 91.0 |\n",
        "| [mobilenet_v2_1.0_192]  | 221 | 3.47 |          70.7 | 90.1 |\n",
        "| [mobilenet_v2_1.0_160]  | 154 | 3.47 |          68.8 | 89.0 |\n",
        "| [mobilenet_v2_1.0_128]  | 99  | 3.47 |          65.3 | 86.9 |\n",
        "| [mobilenet_v2_1.0_96]   | 56  | 3.47 |          60.3 | 83.2 |\n",
        "| [mobilenet_v2_0.75_224] | 209 | 2.61 |          69.8 | 89.6 |\n",
        "| [mobilenet_v2_0.75_192] | 153 | 2.61 |          68.7 | 88.9 |\n",
        "| [mobilenet_v2_0.75_160] | 107 | 2.61 |          66.4 | 87.3 |\n",
        "| [mobilenet_v2_0.75_128] | 69  | 2.61 |          63.2 | 85.3 |\n",
        "| [mobilenet_v2_0.75_96]  | 39  | 2.61 |          58.8 | 81.6 |\n",
        "| [mobilenet_v2_0.5_224]  | 97  | 1.95 |          65.4 | 86.4 |\n",
        "| [mobilenet_v2_0.5_192]  | 71  | 1.95 |          63.9 | 85.4 |\n",
        "| [mobilenet_v2_0.5_160]  | 50  | 1.95 |          61.0 | 83.2 |\n",
        "| [mobilenet_v2_0.5_128]  | 32  | 1.95 |          57.7 | 80.8 |\n",
        "| [mobilenet_v2_0.5_96]   | 18  | 1.95 |          51.2 | 75.8 |\n",
        "| [mobilenet_v2_0.35_224] | 59  | 1.66 |          60.3 | 82.9 |\n",
        "| [mobilenet_v2_0.35_192] | 43  | 1.66 |          58.2 | 81.2 |\n",
        "| [mobilenet_v2_0.35_160] | 30  | 1.66 |          55.7 | 79.1 |\n",
        "| [mobilenet_v2_0.35_128] | 20  | 1.66 |          50.8 | 75.0 |\n",
        "| [mobilenet_v2_0.35_96]  | 11  | 1.66 |          45.5 | 70.4 |\n",
        "\n",
        "The weights for all 16 models are obtained and\n",
        "translated from the Tensorflow checkpoints\n",
        "from TensorFlow checkpoints found [here]\n",
        "(https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/README.md).\n",
        "\n",
        "# Reference\n",
        "\n",
        "This file contains building code for MobileNetV2, based on\n",
        "[MobileNetV2: Inverted Residuals and Linear Bottlenecks]\n",
        "(https://arxiv.org/abs/1801.04381) (CVPR 2018)\n",
        "\n",
        "Tests comparing this model to the existing Tensorflow model can be\n",
        "found at [mobilenet_v2_keras]\n",
        "(https://github.com/JonathanCMitchell/mobilenet_v2_keras)\n",
        "\"\"\"\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "import numpy as np\n",
        "\n",
        "from keras_applications import correct_pad\n",
        "from keras_applications import get_submodules_from_kwargs\n",
        "from keras_applications.imagenet_utils import decode_predictions\n",
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "\n",
        "# TODO Change path to v1.1\n",
        "BASE_WEIGHT_PATH = ('https://github.com/JonathanCMitchell/mobilenet_v2_keras/'\n",
        "                    'releases/download/v1.1/')\n",
        "\n",
        "backend = None\n",
        "layers = None\n",
        "models = None\n",
        "keras_utils = None\n",
        "\n",
        "\n",
        "def preprocess_input(x, **kwargs):\n",
        "    \"\"\"Preprocesses a numpy array encoding a batch of images.\n",
        "\n",
        "    # Arguments\n",
        "        x: a 4D numpy array consists of RGB values within [0, 255].\n",
        "\n",
        "    # Returns\n",
        "        Preprocessed array.\n",
        "    \"\"\"\n",
        "    return imagenet_utils.preprocess_input(x, mode='tf', **kwargs)\n",
        "\n",
        "\n",
        "# This function is taken from the original tf repo.\n",
        "# It ensures that all layers have a channel number that is divisible by 8\n",
        "# It can be seen here:\n",
        "# https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
        "\n",
        "\n",
        "def _make_divisible(v, divisor, min_value=None):\n",
        "    if min_value is None:\n",
        "        min_value = divisor\n",
        "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
        "    # Make sure that round down does not go down by more than 10%.\n",
        "    if new_v < 0.9 * v:\n",
        "        new_v += divisor\n",
        "    return new_v\n",
        "\n",
        "\n",
        "def MobileNetV2(input_shape=None,\n",
        "                alpha=1.0,\n",
        "                include_top=True,\n",
        "                weights='imagenet',\n",
        "                input_tensor=None,\n",
        "                pooling=None,\n",
        "                classes=1000,\n",
        "                **kwargs):\n",
        "    \"\"\"Instantiates the MobileNetV2 architecture.\n",
        "\n",
        "    # Arguments\n",
        "        input_shape: optional shape tuple, to be specified if you would\n",
        "            like to use a model with an input img resolution that is not\n",
        "            (224, 224, 3).\n",
        "            It should have exactly 3 inputs channels (224, 224, 3).\n",
        "            You can also omit this option if you would like\n",
        "            to infer input_shape from an input_tensor.\n",
        "            If you choose to include both input_tensor and input_shape then\n",
        "            input_shape will be used if they match, if the shapes\n",
        "            do not match then we will throw an error.\n",
        "            E.g. `(160, 160, 3)` would be one valid value.\n",
        "        alpha: controls the width of the network. This is known as the\n",
        "        width multiplier in the MobileNetV2 paper, but the name is kept for\n",
        "        consistency with MobileNetV1 in Keras.\n",
        "            - If `alpha` < 1.0, proportionally decreases the number\n",
        "                of filters in each layer.\n",
        "            - If `alpha` > 1.0, proportionally increases the number\n",
        "                of filters in each layer.\n",
        "            - If `alpha` = 1, default number of filters from the paper\n",
        "                 are used at each layer.\n",
        "        include_top: whether to include the fully-connected\n",
        "            layer at the top of the network.\n",
        "        weights: one of `None` (random initialization),\n",
        "              'imagenet' (pre-training on ImageNet),\n",
        "              or the path to the weights file to be loaded.\n",
        "        input_tensor: optional Keras tensor (i.e. output of\n",
        "            `layers.Input()`)\n",
        "            to use as image input for the model.\n",
        "        pooling: Optional pooling mode for feature extraction\n",
        "            when `include_top` is `False`.\n",
        "            - `None` means that the output of the model\n",
        "                will be the 4D tensor output of the\n",
        "                last convolutional block.\n",
        "            - `avg` means that global average pooling\n",
        "                will be applied to the output of the\n",
        "                last convolutional block, and thus\n",
        "                the output of the model will be a\n",
        "                2D tensor.\n",
        "            - `max` means that global max pooling will\n",
        "                be applied.\n",
        "        classes: optional number of classes to classify images\n",
        "            into, only to be specified if `include_top` is True, and\n",
        "            if no `weights` argument is specified.\n",
        "\n",
        "    # Returns\n",
        "        A Keras model instance.\n",
        "\n",
        "    # Raises\n",
        "        ValueError: in case of invalid argument for `weights`,\n",
        "            or invalid input shape or invalid alpha, rows when\n",
        "            weights='imagenet'\n",
        "    \"\"\"\n",
        "    global backend, layers, models, keras_utils\n",
        "    backend, layers, models, keras_utils = get_submodules_from_kwargs(kwargs)\n",
        "\n",
        "    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization), `imagenet` '\n",
        "                         '(pre-training on ImageNet), '\n",
        "                         'or the path to the weights file to be loaded.')\n",
        "\n",
        "    if weights == 'imagenet' and include_top and classes != 1000:\n",
        "        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top` '\n",
        "                         'as true, `classes` should be 1000')\n",
        "\n",
        "    # Determine proper input shape and default size.\n",
        "    # If both input_shape and input_tensor are used, they should match\n",
        "    if input_shape is not None and input_tensor is not None:\n",
        "        try:\n",
        "            is_input_t_tensor = backend.is_keras_tensor(input_tensor)\n",
        "        except ValueError:\n",
        "            try:\n",
        "                is_input_t_tensor = backend.is_keras_tensor(\n",
        "                    keras_utils.get_source_inputs(input_tensor))\n",
        "            except ValueError:\n",
        "                raise ValueError('input_tensor: ', input_tensor,\n",
        "                                 'is not type input_tensor')\n",
        "        if is_input_t_tensor:\n",
        "            if backend.image_data_format == 'channels_first':\n",
        "                if backend.int_shape(input_tensor)[1] != input_shape[1]:\n",
        "                    raise ValueError('input_shape: ', input_shape,\n",
        "                                     'and input_tensor: ', input_tensor,\n",
        "                                     'do not meet the same shape requirements')\n",
        "            else:\n",
        "                if backend.int_shape(input_tensor)[2] != input_shape[1]:\n",
        "                    raise ValueError('input_shape: ', input_shape,\n",
        "                                     'and input_tensor: ', input_tensor,\n",
        "                                     'do not meet the same shape requirements')\n",
        "        else:\n",
        "            raise ValueError('input_tensor specified: ', input_tensor,\n",
        "                             'is not a keras tensor')\n",
        "\n",
        "    # If input_shape is None, infer shape from input_tensor\n",
        "    if input_shape is None and input_tensor is not None:\n",
        "\n",
        "        try:\n",
        "            backend.is_keras_tensor(input_tensor)\n",
        "        except ValueError:\n",
        "            raise ValueError('input_tensor: ', input_tensor,\n",
        "                             'is type: ', type(input_tensor),\n",
        "                             'which is not a valid type')\n",
        "\n",
        "        if input_shape is None and not backend.is_keras_tensor(input_tensor):\n",
        "            default_size = 224\n",
        "        elif input_shape is None and backend.is_keras_tensor(input_tensor):\n",
        "            if backend.image_data_format() == 'channels_first':\n",
        "                rows = backend.int_shape(input_tensor)[2]\n",
        "                cols = backend.int_shape(input_tensor)[3]\n",
        "            else:\n",
        "                rows = backend.int_shape(input_tensor)[1]\n",
        "                cols = backend.int_shape(input_tensor)[2]\n",
        "\n",
        "            if rows == cols and rows in [96, 128, 160, 192, 224]:\n",
        "                default_size = rows\n",
        "            else:\n",
        "                default_size = 224\n",
        "\n",
        "    # If input_shape is None and no input_tensor\n",
        "    elif input_shape is None:\n",
        "        default_size = 224\n",
        "\n",
        "    # If input_shape is not None, assume default size\n",
        "    else:\n",
        "        if backend.image_data_format() == 'channels_first':\n",
        "            rows = input_shape[1]\n",
        "            cols = input_shape[2]\n",
        "        else:\n",
        "            rows = input_shape[0]\n",
        "            cols = input_shape[1]\n",
        "\n",
        "        if rows == cols and rows in [96, 128, 160, 192, 224]:\n",
        "            default_size = rows\n",
        "        else:\n",
        "            default_size = 224\n",
        "\n",
        "    input_shape = _obtain_input_shape(input_shape,\n",
        "                                      default_size=default_size,\n",
        "                                      min_size=32,\n",
        "                                      data_format=backend.image_data_format(),\n",
        "                                      require_flatten=include_top,\n",
        "                                      weights=weights)\n",
        "\n",
        "    if backend.image_data_format() == 'channels_last':\n",
        "        row_axis, col_axis = (0, 1)\n",
        "    else:\n",
        "        row_axis, col_axis = (1, 2)\n",
        "    rows = input_shape[row_axis]\n",
        "    cols = input_shape[col_axis]\n",
        "\n",
        "    if weights == 'imagenet':\n",
        "        if alpha not in [0.35, 0.50, 0.75, 1.0, 1.3, 1.4]:\n",
        "            raise ValueError('If imagenet weights are being loaded, '\n",
        "                             'alpha can be one of `0.35`, `0.50`, `0.75`, '\n",
        "                             '`1.0`, `1.3` or `1.4` only.')\n",
        "\n",
        "        if rows != cols or rows not in [96, 128, 160, 192, 224]:\n",
        "            rows = 224\n",
        "            warnings.warn('`input_shape` is undefined or non-square, '\n",
        "                          'or `rows` is not in [96, 128, 160, 192, 224].'\n",
        "                          ' Weights for input shape (224, 224) will be'\n",
        "                          ' loaded as the default.')\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = layers.Input(shape=input_shape)\n",
        "    else:\n",
        "        if not backend.is_keras_tensor(input_tensor):\n",
        "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "\n",
        "    channel_axis = 1 if backend.image_data_format() == 'channels_first' else -1\n",
        "\n",
        "    first_block_filters = _make_divisible(32 * alpha, 8)\n",
        "    x = layers.ZeroPadding2D(padding=correct_pad(backend, img_input, 3),\n",
        "                             name='Conv1_pad')(img_input)\n",
        "    x = layers.Conv2D(first_block_filters,\n",
        "                      kernel_size=3,\n",
        "                      strides=(2, 2),\n",
        "                      padding='valid',\n",
        "                      use_bias=False,\n",
        "                      name='Conv1')(x)\n",
        "    x = layers.BatchNormalization(axis=channel_axis,\n",
        "                                  epsilon=1e-3,\n",
        "                                  momentum=0.999,\n",
        "                                  name='bn_Conv1')(x)\n",
        "    x = layers.ReLU(6., name='Conv1_relu')(x)\n",
        "\n",
        "    x = _inverted_res_block(x, filters=16, alpha=alpha, stride=1,\n",
        "                            expansion=1, block_id=0)\n",
        "\n",
        "    x = _inverted_res_block(x, filters=24, alpha=alpha, stride=2,\n",
        "                            expansion=6, block_id=1)\n",
        "    x = _inverted_res_block(x, filters=24, alpha=alpha, stride=1,\n",
        "                            expansion=6, block_id=2)\n",
        "\n",
        "    x = _inverted_res_block(x, filters=32, alpha=alpha, stride=2,\n",
        "                            expansion=6, block_id=3)\n",
        "    x = _inverted_res_block(x, filters=32, alpha=alpha, stride=1,\n",
        "                            expansion=6, block_id=4)\n",
        "    x = _inverted_res_block(x, filters=32, alpha=alpha, stride=1,\n",
        "                            expansion=6, block_id=5)\n",
        "\n",
        "    x = _inverted_res_block(x, filters=64, alpha=alpha, stride=2,\n",
        "                            expansion=6, block_id=6)\n",
        "    x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1,\n",
        "                            expansion=6, block_id=7)\n",
        "    x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1,\n",
        "                            expansion=6, block_id=8)\n",
        "    x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1,\n",
        "                            expansion=6, block_id=9)\n",
        "\n",
        "    x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1,\n",
        "                            expansion=6, block_id=10)\n",
        "    x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1,\n",
        "                            expansion=6, block_id=11)\n",
        "    x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1,\n",
        "                            expansion=6, block_id=12)\n",
        "\n",
        "    x = _inverted_res_block(x, filters=160, alpha=alpha, stride=2,\n",
        "                            expansion=6, block_id=13)\n",
        "    x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1,\n",
        "                            expansion=6, block_id=14)\n",
        "    x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1,\n",
        "                            expansion=6, block_id=15)\n",
        "\n",
        "    x = _inverted_res_block(x, filters=320, alpha=alpha, stride=1,\n",
        "                            expansion=6, block_id=16)\n",
        "\n",
        "    # no alpha applied to last conv as stated in the paper:\n",
        "    # if the width multiplier is greater than 1 we\n",
        "    # increase the number of output channels\n",
        "    if alpha > 1.0:\n",
        "        last_block_filters = _make_divisible(1280 * alpha, 8)\n",
        "    else:\n",
        "        last_block_filters = 1280\n",
        "\n",
        "    x = layers.Conv2D(last_block_filters,\n",
        "                      kernel_size=1,\n",
        "                      use_bias=False,\n",
        "                      name='Conv_1')(x)\n",
        "    x = layers.BatchNormalization(axis=channel_axis,\n",
        "                                  epsilon=1e-3,\n",
        "                                  momentum=0.999,\n",
        "                                  name='Conv_1_bn')(x)\n",
        "    x = layers.ReLU(6., name='out_relu')(x)\n",
        "\n",
        "    if include_top:\n",
        "        x = layers.GlobalAveragePooling2D()(x)\n",
        "        x = layers.Dense(classes, activation='softmax',\n",
        "                         use_bias=True, name='Logits')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = layers.GlobalAveragePooling2D()(x)\n",
        "        elif pooling == 'max':\n",
        "            x = layers.GlobalMaxPooling2D()(x)\n",
        "\n",
        "    # Ensure that the model takes into account\n",
        "    # any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = keras_utils.get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "\n",
        "    # Create model.\n",
        "    model = models.Model(inputs, x,\n",
        "                         name='mobilenetv2_%0.2f_%s' % (alpha, rows))\n",
        "\n",
        "    # Load weights.\n",
        "    if weights == 'imagenet':\n",
        "        if include_top:\n",
        "            model_name = ('mobilenet_v2_weights_tf_dim_ordering_tf_kernels_' +\n",
        "                          str(alpha) + '_' + str(rows) + '.h5')\n",
        "            weight_path = BASE_WEIGHT_PATH + model_name\n",
        "            weights_path = keras_utils.get_file(\n",
        "                model_name, weight_path, cache_subdir='models')\n",
        "        else:\n",
        "            model_name = ('mobilenet_v2_weights_tf_dim_ordering_tf_kernels_' +\n",
        "                          str(alpha) + '_' + str(rows) + '_no_top' + '.h5')\n",
        "            weight_path = BASE_WEIGHT_PATH + model_name\n",
        "            weights_path = keras_utils.get_file(\n",
        "                model_name, weight_path, cache_subdir='models')\n",
        "        model.load_weights(weights_path)\n",
        "    elif weights is not None:\n",
        "        model.load_weights(weights)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def _inverted_res_block(inputs, expansion, stride, alpha, filters, block_id):\n",
        "    channel_axis = 1 if backend.image_data_format() == 'channels_first' else -1\n",
        "\n",
        "    in_channels = backend.int_shape(inputs)[channel_axis]\n",
        "    pointwise_conv_filters = int(filters * alpha)\n",
        "    pointwise_filters = _make_divisible(pointwise_conv_filters, 8)\n",
        "    x = inputs\n",
        "    prefix = 'block_{}_'.format(block_id)\n",
        "\n",
        "    if block_id:\n",
        "        # Expand\n",
        "        x = layers.Conv2D(expansion * in_channels,\n",
        "                          kernel_size=1,\n",
        "                          padding='same',\n",
        "                          use_bias=False,\n",
        "                          activation=None,\n",
        "                          name=prefix + 'expand')(x)\n",
        "        x = layers.BatchNormalization(axis=channel_axis,\n",
        "                                      epsilon=1e-3,\n",
        "                                      momentum=0.999,\n",
        "                                      name=prefix + 'expand_BN')(x)\n",
        "        x = layers.ReLU(6., name=prefix + 'expand_relu')(x)\n",
        "    else:\n",
        "        prefix = 'expanded_conv_'\n",
        "\n",
        "    # Depthwise\n",
        "    if stride == 2:\n",
        "        x = layers.ZeroPadding2D(padding=correct_pad(backend, x, 3),\n",
        "                                 name=prefix + 'pad')(x)\n",
        "    x = layers.DepthwiseConv2D(kernel_size=3,\n",
        "                               strides=stride,\n",
        "                               activation=None,\n",
        "                               use_bias=False,\n",
        "                               padding='same' if stride == 1 else 'valid',\n",
        "                               name=prefix + 'depthwise')(x)\n",
        "    x = layers.BatchNormalization(axis=channel_axis,\n",
        "                                  epsilon=1e-3,\n",
        "                                  momentum=0.999,\n",
        "                                  name=prefix + 'depthwise_BN')(x)\n",
        "\n",
        "    x = layers.ReLU(6., name=prefix + 'depthwise_relu')(x)\n",
        "\n",
        "    # Project\n",
        "    x = layers.Conv2D(pointwise_filters,\n",
        "                      kernel_size=1,\n",
        "                      padding='same',\n",
        "                      use_bias=False,\n",
        "                      activation=None,\n",
        "                      name=prefix + 'project')(x)\n",
        "    x = layers.BatchNormalization(axis=channel_axis,\n",
        "                                  epsilon=1e-3,\n",
        "                                  momentum=0.999,\n",
        "                                  name=prefix + 'project_BN')(x)\n",
        "\n",
        "    if in_channels == pointwise_filters and stride == 1:\n",
        "        return layers.Add(name=prefix + 'add')([inputs, x])\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDf1G53XedPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate(batch):\n",
        "  num_classes = 100\n",
        "  \n",
        "  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data(label_mode='fine')\n",
        "  y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "  y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "  datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "      featurewise_center=True,\n",
        "      featurewise_std_normalization=True,\n",
        "      rotation_range=20,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      horizontal_flip=True)\n",
        "\n",
        "  # compute quantities required for featurewise normalization\n",
        "  # (std, mean, and principal components if ZCA whitening is applied)\n",
        "  datagen.fit(x_train)\n",
        "  \n",
        "  train_generator = datagen.flow(x_train, y_train, batch_size=batch)\n",
        "  steps_per_epoch = len(x_train) / batch\n",
        "  \n",
        "  return train_generator, steps_per_epoch\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc1HvkXbprUZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "e7094b59-fd1f-4300-d5d0-c9dcba26a680"
      },
      "source": [
        "tf.keras.backend._get_available_gpus()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-cb1bb597510e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_available_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation_wrapper.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_dw_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accessing local variables before they are created.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dw_wrapped_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     if (self._dw_warning_count < _PER_MODULE_WARNING_LIMIT and\n\u001b[1;32m    108\u001b[0m         name not in self._dw_deprecated_printed):\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.python.keras.api._v1.keras.backend' has no attribute '_get_available_gpus'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BECcocg_YqEW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "outputId": "97ba80ae-ceba-473e-fac7-f8dc076d5473"
      },
      "source": [
        "epochs = 10\n",
        "\n",
        "model = MobileNetV2(input_shape=[32,32,3],\n",
        "                alpha=1.0,\n",
        "                include_top=True,\n",
        "                weights=None,\n",
        "                input_tensor=None,\n",
        "                pooling=None,\n",
        "                classes=100,\n",
        "                backend = tf.keras.backend,\n",
        "                layers = tf.keras.layers,\n",
        "                models = tf.keras.models,\n",
        "                utils = tf.keras.utils)\n",
        "\n",
        "# opt = Adam()\n",
        "# earlystop = EarlyStopping(monitor='val_acc', patience=30, verbose=0, mode='auto')\n",
        "# model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "model.compile(\n",
        "      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, ),\n",
        "      loss='categorical_crossentropy',\n",
        "      metrics=['accuracy'])\n",
        "\n",
        "train_generator, steps_per_epoch = generate(32)\n",
        "\n",
        "hist = model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        epochs=epochs)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0704 15:33:06.071527 140704122214272 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 11s 0us/step\n",
            "Epoch 1/10\n",
            "1563/1562 [==============================] - 135s 86ms/step - loss: 4.4353 - acc: 0.0437\n",
            "Epoch 2/10\n",
            "1563/1562 [==============================] - 122s 78ms/step - loss: 4.0480 - acc: 0.0769\n",
            "Epoch 3/10\n",
            "1563/1562 [==============================] - 121s 77ms/step - loss: 3.9116 - acc: 0.0906\n",
            "Epoch 4/10\n",
            "1563/1562 [==============================] - 121s 77ms/step - loss: 3.8756 - acc: 0.0933\n",
            "Epoch 5/10\n",
            " 434/1562 [=======>......................] - ETA: 1:24 - loss: 3.7806 - acc: 0.1064"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-9a7f2c74c9be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         epochs=epochs)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1173\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3Ih1cQhaqFQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "outputId": "f9073500-3f15-4cb5-e93b-73cd3a9cc4d3"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "train_generator, steps_per_epoch = generate(32)\n",
        "\n",
        "model = MobileNetV2(input_shape=[32,32,3],\n",
        "                    alpha=1.0,\n",
        "                    include_top=True,\n",
        "                    weights=None,\n",
        "                    input_tensor=None,\n",
        "                    pooling=None,\n",
        "                    classes=100,\n",
        "                    backend = tf.keras.backend,\n",
        "                    layers = tf.keras.layers,\n",
        "                    models = tf.keras.models,\n",
        "                    utils = tf.keras.utils)\n",
        "\n",
        "\n",
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "        model,\n",
        "        strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://'    + os.environ['COLAB_TPU_ADDR'])\n",
        "        )\n",
        "    )\n",
        "tpu_model.compile(\n",
        "        optimizer=tf.train.AdamOptimizer(learning_rate=5e-2),\n",
        "        loss= tf.keras.losses.categorical_crossentropy,\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "checkpoint_path = \"path/weights.{epoch:02d}-{val_loss:.2f}.hdf5\"                             \n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        checkpoint_path, verbose=1, save_weights_only=True,\n",
        "        period=5)\n",
        "\n",
        "tpu_model.fit_generator(\n",
        "        generator=train_generator,\n",
        "        epochs=10,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        callbacks=[cp_callback]\n",
        "    )"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0704 15:29:22.387421 140063949072256 keras_support.py:217] Keras support is now deprecated in support of TPU Strategy. Please follow the distribution strategy guide on tensorflow.org to migrate to the 2.0 supported version.\n",
            "W0704 15:29:43.366959 140063949072256 keras_support.py:1394] Keras support is now deprecated in support of TPU Strategy. Please follow the distribution strategy guide on tensorflow.org to migrate to the 2.0 supported version.\n",
            "W0704 15:29:43.576986 140063949072256 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ecf771efc2bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcp_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0msamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_samples_or_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Handle ProgBar as part of Callbacks once hooks are ready.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       mode=mode)\n\u001b[0m\u001b[1;32m    179\u001b[0m   \u001b[0;31m# TODO(omalleyt): Handle ProgBar as part of Callbacks once hooks are ready.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m   \u001b[0mprogbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mconfigure_callbacks\u001b[0;34m(callbacks, model, do_validation, batch_size, epochs, steps_per_epoch, samples, verbose, count_mode, mode)\u001b[0m\n\u001b[1;32m    118\u001b[0m   \u001b[0mcallback_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mcallback_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ckpt_saved_epoch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0;31m# The attribute `_ckpt_saved_epoch` is supposed to be None at the start of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;31m# training (it should be made None at the end of successful multi-worker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KerasTPUModel' object has no attribute '_ckpt_saved_epoch'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq-nvpDAmFXi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c536b0bb-2e4c-4883-a4ea-5a520735bcc3"
      },
      "source": [
        "import os\n",
        "\n",
        "resolver = tf.contrib.cluster_resolver.TPUClusterResolver('grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.contrib.distribute.initialize_tpu_system(resolver)\n",
        "strategy = tf.contrib.distribute.TPUStrategy(resolver)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data(label_mode='fine')\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 100)\n",
        "\n",
        "with strategy.scope():\n",
        "  model = MobileNetV2(input_shape=[32,32,3],\n",
        "                    alpha=1.0,\n",
        "                    include_top=True,\n",
        "                    weights=None,\n",
        "                    input_tensor=None,\n",
        "                    pooling=None,\n",
        "                    classes=100,\n",
        "                    backend = tf.keras.backend,\n",
        "                    layers = tf.keras.layers,\n",
        "                    models = tf.keras.models,\n",
        "                    utils = tf.keras.utils)\n",
        "  model.compile(\n",
        "      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, ),\n",
        "      loss='categorical_crossentropy',\n",
        "      metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0704 16:01:07.547580 139690312136576 tpu_strategy_util.py:56] TPU system %s has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "50/50 [==============================] - 21s 416ms/step - loss: 4.5147 - acc: 0.0332\n",
            "Epoch 2/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 4.0350 - acc: 0.0792\n",
            "Epoch 3/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 3.7746 - acc: 0.1167\n",
            "Epoch 4/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 3.5757 - acc: 0.1490\n",
            "Epoch 5/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 3.4133 - acc: 0.1760\n",
            "Epoch 6/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 3.2946 - acc: 0.1972\n",
            "Epoch 7/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 3.1704 - acc: 0.2197\n",
            "Epoch 8/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 3.0667 - acc: 0.2390\n",
            "Epoch 9/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 2.9786 - acc: 0.2549\n",
            "Epoch 10/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 2.8787 - acc: 0.2728\n",
            "Epoch 11/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 2.8015 - acc: 0.2890\n",
            "Epoch 12/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 2.7220 - acc: 0.3042\n",
            "Epoch 13/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 2.6420 - acc: 0.3199\n",
            "Epoch 14/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 2.5644 - acc: 0.3332\n",
            "Epoch 15/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 2.4772 - acc: 0.3512\n",
            "Epoch 16/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 2.4227 - acc: 0.3616\n",
            "Epoch 17/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 2.3409 - acc: 0.3776\n",
            "Epoch 18/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 2.2652 - acc: 0.3935\n",
            "Epoch 19/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 2.2104 - acc: 0.4055\n",
            "Epoch 20/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 2.1496 - acc: 0.4157\n",
            "Epoch 21/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 2.0636 - acc: 0.4380\n",
            "Epoch 22/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 2.0061 - acc: 0.4510\n",
            "Epoch 23/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 1.9404 - acc: 0.4646\n",
            "Epoch 24/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 1.8778 - acc: 0.4778\n",
            "Epoch 25/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 1.8271 - acc: 0.4894\n",
            "Epoch 26/200\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 1.7667 - acc: 0.5036\n",
            "Epoch 27/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 1.6769 - acc: 0.5266\n",
            "Epoch 28/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 1.6142 - acc: 0.5379\n",
            "Epoch 29/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 1.5552 - acc: 0.5542\n",
            "Epoch 30/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 1.4922 - acc: 0.5676\n",
            "Epoch 31/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 1.4632 - acc: 0.5721\n",
            "Epoch 32/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 1.3896 - acc: 0.5959\n",
            "Epoch 33/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 1.3443 - acc: 0.6017\n",
            "Epoch 34/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 1.2760 - acc: 0.6250\n",
            "Epoch 35/200\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 1.2307 - acc: 0.6346\n",
            "Epoch 36/200\n",
            "50/50 [==============================] - 2s 43ms/step - loss: 1.1880 - acc: 0.6456\n",
            "Epoch 37/200\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 1.1204 - acc: 0.6634\n",
            "Epoch 38/200\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 1.0848 - acc: 0.6746\n",
            "Epoch 39/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 1.0391 - acc: 0.6866\n",
            "Epoch 40/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.9787 - acc: 0.7039\n",
            "Epoch 41/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.9328 - acc: 0.7157\n",
            "Epoch 42/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.9431 - acc: 0.7107\n",
            "Epoch 43/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.8897 - acc: 0.7257\n",
            "Epoch 44/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.8244 - acc: 0.7435\n",
            "Epoch 45/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.8003 - acc: 0.7504\n",
            "Epoch 46/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.7621 - acc: 0.7654\n",
            "Epoch 47/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.7054 - acc: 0.7806\n",
            "Epoch 48/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.6828 - acc: 0.7862\n",
            "Epoch 49/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.6406 - acc: 0.7992\n",
            "Epoch 50/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.6104 - acc: 0.8085\n",
            "Epoch 51/200\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.6069 - acc: 0.8082\n",
            "Epoch 52/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.5701 - acc: 0.8194\n",
            "Epoch 53/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.5555 - acc: 0.8242\n",
            "Epoch 54/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.5604 - acc: 0.8231\n",
            "Epoch 55/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.5339 - acc: 0.8302\n",
            "Epoch 56/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.5128 - acc: 0.8362\n",
            "Epoch 57/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.4916 - acc: 0.8455\n",
            "Epoch 58/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.4622 - acc: 0.8526\n",
            "Epoch 59/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.4582 - acc: 0.8531\n",
            "Epoch 60/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.4499 - acc: 0.8559\n",
            "Epoch 61/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.4325 - acc: 0.8623\n",
            "Epoch 62/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.3899 - acc: 0.8750\n",
            "Epoch 63/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.3884 - acc: 0.8780\n",
            "Epoch 64/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.3894 - acc: 0.8757\n",
            "Epoch 65/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.3802 - acc: 0.8798\n",
            "Epoch 66/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.3802 - acc: 0.8780\n",
            "Epoch 67/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.3775 - acc: 0.8796\n",
            "Epoch 68/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.3582 - acc: 0.8850\n",
            "Epoch 69/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.3463 - acc: 0.8913\n",
            "Epoch 70/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.3389 - acc: 0.8894\n",
            "Epoch 71/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.3278 - acc: 0.8948\n",
            "Epoch 72/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.3271 - acc: 0.8951\n",
            "Epoch 73/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.3470 - acc: 0.8879\n",
            "Epoch 74/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.3505 - acc: 0.8876\n",
            "Epoch 75/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.3366 - acc: 0.8923\n",
            "Epoch 76/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.3031 - acc: 0.9023\n",
            "Epoch 77/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2819 - acc: 0.9104\n",
            "Epoch 78/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2967 - acc: 0.9051\n",
            "Epoch 79/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2716 - acc: 0.9122\n",
            "Epoch 80/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2622 - acc: 0.9164\n",
            "Epoch 81/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2737 - acc: 0.9129\n",
            "Epoch 82/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.2778 - acc: 0.9102\n",
            "Epoch 83/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2727 - acc: 0.9119\n",
            "Epoch 84/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2618 - acc: 0.9155\n",
            "Epoch 85/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2785 - acc: 0.9105\n",
            "Epoch 86/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2739 - acc: 0.9127\n",
            "Epoch 87/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2919 - acc: 0.9072\n",
            "Epoch 88/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2737 - acc: 0.9110\n",
            "Epoch 89/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2667 - acc: 0.9139\n",
            "Epoch 90/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2537 - acc: 0.9185\n",
            "Epoch 91/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2400 - acc: 0.9239\n",
            "Epoch 92/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2507 - acc: 0.9194\n",
            "Epoch 93/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.2314 - acc: 0.9253\n",
            "Epoch 94/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2200 - acc: 0.9284\n",
            "Epoch 95/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.2349 - acc: 0.9231\n",
            "Epoch 96/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.2247 - acc: 0.9283\n",
            "Epoch 97/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.2300 - acc: 0.9263\n",
            "Epoch 98/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.2423 - acc: 0.9221\n",
            "Epoch 99/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.2424 - acc: 0.9220\n",
            "Epoch 100/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.2354 - acc: 0.9228\n",
            "Epoch 101/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2271 - acc: 0.9252\n",
            "Epoch 102/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2290 - acc: 0.9264\n",
            "Epoch 103/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2233 - acc: 0.9277\n",
            "Epoch 104/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.2166 - acc: 0.9302\n",
            "Epoch 105/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2282 - acc: 0.9267\n",
            "Epoch 106/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2163 - acc: 0.9302\n",
            "Epoch 107/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.2094 - acc: 0.9320\n",
            "Epoch 108/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1969 - acc: 0.9367\n",
            "Epoch 109/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.1977 - acc: 0.9367\n",
            "Epoch 110/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2132 - acc: 0.9326\n",
            "Epoch 111/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2139 - acc: 0.9303\n",
            "Epoch 112/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2057 - acc: 0.9329\n",
            "Epoch 113/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.2093 - acc: 0.9317\n",
            "Epoch 114/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.2075 - acc: 0.9330\n",
            "Epoch 115/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1933 - acc: 0.9391\n",
            "Epoch 116/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.1860 - acc: 0.9404\n",
            "Epoch 117/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1848 - acc: 0.9394\n",
            "Epoch 118/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.1908 - acc: 0.9386\n",
            "Epoch 119/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2018 - acc: 0.9339\n",
            "Epoch 120/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2180 - acc: 0.9305\n",
            "Epoch 121/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.2119 - acc: 0.9312\n",
            "Epoch 122/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1957 - acc: 0.9370\n",
            "Epoch 123/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1813 - acc: 0.9421\n",
            "Epoch 124/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1857 - acc: 0.9398\n",
            "Epoch 125/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1822 - acc: 0.9406\n",
            "Epoch 126/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.1882 - acc: 0.9389\n",
            "Epoch 127/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1914 - acc: 0.9390\n",
            "Epoch 128/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1855 - acc: 0.9401\n",
            "Epoch 129/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1793 - acc: 0.9425\n",
            "Epoch 130/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1693 - acc: 0.9451\n",
            "Epoch 131/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.1676 - acc: 0.9444\n",
            "Epoch 132/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1657 - acc: 0.9454\n",
            "Epoch 133/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1681 - acc: 0.9457\n",
            "Epoch 134/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1634 - acc: 0.9467\n",
            "Epoch 135/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1603 - acc: 0.9474\n",
            "Epoch 136/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1770 - acc: 0.9432\n",
            "Epoch 137/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.1947 - acc: 0.9374\n",
            "Epoch 138/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1916 - acc: 0.9367\n",
            "Epoch 139/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1756 - acc: 0.9430\n",
            "Epoch 140/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1775 - acc: 0.9416\n",
            "Epoch 141/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1717 - acc: 0.9446\n",
            "Epoch 142/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.1566 - acc: 0.9489\n",
            "Epoch 143/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1595 - acc: 0.9483\n",
            "Epoch 144/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1467 - acc: 0.9523\n",
            "Epoch 145/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1548 - acc: 0.9495\n",
            "Epoch 146/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1642 - acc: 0.9463\n",
            "Epoch 147/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1738 - acc: 0.9437\n",
            "Epoch 148/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1694 - acc: 0.9455\n",
            "Epoch 149/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1667 - acc: 0.9460\n",
            "Epoch 150/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1548 - acc: 0.9490\n",
            "Epoch 151/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1510 - acc: 0.9511\n",
            "Epoch 152/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1627 - acc: 0.9470\n",
            "Epoch 153/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1661 - acc: 0.9468\n",
            "Epoch 154/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1535 - acc: 0.9501\n",
            "Epoch 155/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1479 - acc: 0.9522\n",
            "Epoch 156/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1456 - acc: 0.9533\n",
            "Epoch 157/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1551 - acc: 0.9495\n",
            "Epoch 158/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1496 - acc: 0.9526\n",
            "Epoch 159/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1428 - acc: 0.9540\n",
            "Epoch 160/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1411 - acc: 0.9549\n",
            "Epoch 161/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1475 - acc: 0.9521\n",
            "Epoch 162/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1564 - acc: 0.9502\n",
            "Epoch 163/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1477 - acc: 0.9520\n",
            "Epoch 164/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.1497 - acc: 0.9511\n",
            "Epoch 165/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.1457 - acc: 0.9539\n",
            "Epoch 166/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.1450 - acc: 0.9533\n",
            "Epoch 167/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.1358 - acc: 0.9563\n",
            "Epoch 168/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.1320 - acc: 0.9576\n",
            "Epoch 169/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1266 - acc: 0.9589\n",
            "Epoch 170/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1332 - acc: 0.9570\n",
            "Epoch 171/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1424 - acc: 0.9541\n",
            "Epoch 172/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.1426 - acc: 0.9538\n",
            "Epoch 173/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1409 - acc: 0.9548\n",
            "Epoch 174/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1361 - acc: 0.9568\n",
            "Epoch 175/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.1335 - acc: 0.9569\n",
            "Epoch 176/200\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.1335 - acc: 0.9570\n",
            "Epoch 177/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1385 - acc: 0.9542\n",
            "Epoch 178/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1452 - acc: 0.9524\n",
            "Epoch 179/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1527 - acc: 0.9517\n",
            "Epoch 180/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1616 - acc: 0.9479\n",
            "Epoch 181/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1560 - acc: 0.9485\n",
            "Epoch 182/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1454 - acc: 0.9528\n",
            "Epoch 183/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1295 - acc: 0.9581\n",
            "Epoch 184/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1247 - acc: 0.9598\n",
            "Epoch 185/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1201 - acc: 0.9607\n",
            "Epoch 186/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1234 - acc: 0.9608\n",
            "Epoch 187/200\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.1151 - acc: 0.9628\n",
            "Epoch 188/200\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.1208 - acc: 0.9607\n",
            "Epoch 189/200\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.1242 - acc: 0.9604\n",
            "Epoch 190/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1167 - acc: 0.9630\n",
            "Epoch 191/200\n",
            "50/50 [==============================] - 2s 43ms/step - loss: 0.1209 - acc: 0.9616\n",
            "Epoch 192/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1228 - acc: 0.9604\n",
            "Epoch 193/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1145 - acc: 0.9626\n",
            "Epoch 194/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1221 - acc: 0.9607\n",
            "Epoch 195/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1305 - acc: 0.9585\n",
            "Epoch 196/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1152 - acc: 0.9621\n",
            "Epoch 197/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1262 - acc: 0.9586\n",
            "Epoch 198/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1275 - acc: 0.9599\n",
            "Epoch 199/200\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1374 - acc: 0.9555\n",
            "Epoch 200/200\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1306 - acc: 0.9572\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0b9d952860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boIkuh4Hq22x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(\n",
        "    x_train.astype(np.float32), y_train.astype(np.float32),\n",
        "    epochs=200,\n",
        "    steps_per_epoch=50\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}